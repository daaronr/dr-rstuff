---
title: "marking-mcq-code - for bee2038 - 2020"
author: "David Reinstein"
date: "11/2/2019 adapted 14 Jan 2020"
output: html_document
---

# Outline of code and procedure

1. mark_scheme: ms <- Input 'marking.csv' file of q_label, point_value, d_partial_credit, num_ans (number of possible answers per question, typically 5), c_ans (correct_answers), alt_ans (alternate correct, where non-blank), free_marks (grant everyone this share of marks for a question as a minimum)

- Convert correct_answers, alt_correct to character lists

2. student_responses: sr <- Input (key sheet and rows of) Excel file of student_id, r_q_[label] (responses to all questions, same order as for marking.csv) as produced by Exeter MCQ administrative processing; each row is a student

3. Clean student_responses file to aid processing:

- dataframe or matrix; each r_q[label] is a list of responses chosen ("A","C","E") etc
- clean each response to have the same format as mark_scheme$correct_answers (capital letters etc)

4. Create additional 'sr$m_pct_q_[label]' columns^[note, this could also be done by creating a different matrix, or a multidimensional array] in sr, one for each question, calculating 'share of marks to be awarded' as follows

Comparing `ms$c_ans` and `student_responses$response_q` element-by-element

- If d_partial_credit = 0, then sr$m_pct_q_[label] <= ifelse 'exact match' 1,0

- If d_partial_credit = 1, then
  - Share of correct: (sum 'list elements in common') / length(`ms$q_label`)
  - less 'Share of incorrect': ((length(`ms$q_label`) - sum 'list elements in common')) / `(ms$num_ans - length(ms$c_ans)`)

- if `length$alt_ans>0` do the previous step again wrt `alt_ans`, assigning a column sr$alt_m_pct_q_[label]

- set `sr$max_m_pct_q_[label]` to max of 0, `sr$alt_m_pct_q_[]`,  `sr$m_pct_q_[]`, `sr$free_marks` (note no negative marks for a question, award best possible mark for all alternate answers)

5. Take product of `ms$point_value`  and `sr$max_m_pct_q_[label]` element by element for each student and question, creating `sr$mark_q_[label]` columns.

6. `sr$total_mark <- ` Sum `sr$mark_q_[label]` for each student to get overall mark.

7. Output as organised excel sheet (and other formats to give individual students their breakdowns?)


# Setup

```{r local_values}

folder <- "/Users/yosemite/OneDrive - University of Exeter/exeterteaching_newer/marking/be2038_final_20_marking"

markscheme <- "mark_scheme.csv"
longansfile <- "2038finalmark2020-Grid view_all.csv"
student_responses <-  "Copy of BEE2038 Answers.xlsx"
#student_responses <- "BEE2038 - data - not marked.xlsx"
#student_responses <- "bee2038-midterm-2019-extra-ilp.xlsx"
official_sheet <- "BEE2038_official_marksheet.xlsx"

#adhoc_adjust - done at bottom <- 3+
  #Marks added for questions where top-20% didn't get it.

outfile <-  "bee2038_final_results_20.csv"
outfile_uni_order <-  "bee2038_final_results_20_uni_order.csv"

```


```{r library, include=TRUE, warning=FALSE, echo=FALSE}

knitr::opts_chunk$set(echo = TRUE)
require("knitr")

opts_knit$set(root.dir = folder)

library(pacman)
#knitr,dplyr,tidyverse,labelled,citr,reporttools,magrittr,glue,huxtable,experiment,dataMaid,broom,janitor,here,xRStata,estimatr,xtable
p_load(dplyr,magrittr,purrr,tidyverse,tidyr,broom,janitor, here,glue,dataMaid,readr,lubridate,summarytools, httr,jsonlite,rlist,XML, readxl)

```

Just go to the relevant directory  - set above I think
```{r}

#setwd(folder)

```


# 1. mark_scheme: ms <- Input 'marking.csv' file

```{r input-mark-scheme}

ms <- read.csv(paste(folder,"/",markscheme, sep = ""), header=TRUE,  stringsAsFactors=FALSE, row.names = 1)

```

Convert correct_answers, alt_correct to character lists:

```{r}

ms$c_ans <- lapply(strsplit(as.character(ms$c_ans),split=','),trimws)
ms$alt_ans <- lapply(strsplit(as.character(ms$alt_ans),split=','),trimws)

```

Count number of correct answers
```{r}

for (i in 1:NROW(ms)) {
ms$numc[i] <- length(ms$c_ans[[i]])
ms$numc_a[i] <- length(ms$alt_ans[[i]])
}
```

2. student_responses
3. Clean student_responses file

# Input mark sheet, remove garbage 

sr <- input mark sheet, remove parens

```{r}

sr <- read_excel(paste(folder, "/", student_responses, sep = ""))


#remove if no candidate number
sr <- sr %>% filter(!is.na(`Student Candidate Number`)) %>%
  filter(!grepl("\\D", `Student Candidate Number`))

sr <- lapply(sr, gsub, pattern = ")", replacement = "", fixed = TRUE)
sr <- lapply(sr, gsub, pattern = "(", replacement = "", fixed = TRUE)
sr <- lapply(sr, gsub, pattern = "BLANK", replacement = "", fixed = TRUE)

sr <- as_tibble(sr)
```

Convert all but the first column to a list column:
```{r}

sr_base <- sr # preserve original; crappy workaround

makeitlist <- function(x) (lapply(strsplit(as.character(x),split=','),trimws))

for (i in 2:length(sr)) {
  sr[[i]] <- makeitlist(sr[[i]])
}

```

# Marking process

4. Create additional 'sr$m_pct_q_[label]' 'share of marks to be awarded' as follows

Compare `ms$c_ans` and `sr$response_q` element-by-element and count number of matches


```{r count-matches-to-correct-ans}

#This seems to work, element by element...
#length(intersect(sr$questions3[[2]], ms[[c("questions3"),"c_ans"]]))
#length(intersect(sr$questions3[[1]], ms[[c("questions3"),"c_ans"]]))

#now iterate it over all questions and over all students

for(q in rownames(ms)) {   #iterate over all questions
  for (i in 1:NROW(sr)) {  #over all students
    sr[[glue("cr_ans_",q)]][[i]] <- length(intersect(sr[[q]][[i]], ms[[c(q),"c_ans"]]))
  }
}
```


- If d_partial_credit = 0, then sr$m_pct_q_[label] <= ifelse 'exact match' 1,0

- If d_partial_credit = 1, then
  - Share of correct: (sum 'list elements in common') / length(`ms$q_label`)
  - less 'Share of incorrect': ((length(`ms$q_label`) - sum 'list elements in common')) / `(ms$num_ans - length(ms$c_ans)`)

```{r award-marks}

#- If d_partial_credit = 0, then sr$m_pct_q_[label] <= ifelse 'exact match' 1,0

for(q in rownames(ms)) {   #iterate over all questions
  for (i in 1:NROW(sr)) {  #over all students
    sr[[glue("sh_cor",q)]][[i]]   <- sr[[glue("cr_ans_",q)]][[i]]/length(ms[[c(q),"c_ans"]]) #share of correct answers attained
    sr[[glue("sh_incor",q)]][[i]] <-  (length(sr[[q]][[i]])-sr[[glue("cr_ans_",q)]][[i]])/(ms[[c(q),"num_choices"]] - length(ms[[c(q),"c_ans"]])) #share of incorrect answers chosen
    sr[[glue("net_cor",q)]][[i]] <- max(0,sr[[glue("sh_cor",q)]][[i]]-sr[[glue("sh_incor",q)]][[i]])  #net positive, minimum 0
    sr[[glue("mk_",q)]][[i]] <- sr[[glue("net_cor",q)]][[i]] *ms[[c(q),"point_value"]] #multiply by point value
    sr[[glue("pv_",q)]][[i]] <- ms[[c(q),"point_value"]] #point value variable
#NOTE: this is exactly the redundancy I was trying to avoid.
    sr[[glue("mk_",q)]][[i]] <- sr[[glue("mk_",q)]][[i]]*(ms[[c(q),"d_partial_credit"]]) +  sr[[glue("mk_",q)]][[i]]*(1-(ms[[c(q),"d_partial_credit"]]))*(sr[[glue("sh_incor",q)]][[i]]==0) # Set imperfect answers to 0 where no partial credit is granted
    sr[[glue("markpct_",q)]][[i]] <-  sr[[glue("mk_",q)]][[i]]/sr[[glue("pv_",q)]][[i]] #share of points
#NOT
  }
}

sr <- sr %>%
  select(-matches("sh_cor|sh_incor|net_|cr_"))

```

Marks based on alternate correct answers:
```{r}

for(q in rownames(ms)) {   #iterate over all questions 
  for (i in 1:NROW(sr)) {  #over all students
    sr[[glue("cr_ans_alt",q)]][[i]] <- length(intersect(sr[[q]][[i]], ms[[c(q),"alt_ans"]])) 
  }
}

for(q in rownames(ms)) {   #iterate over all questions 
  for (i in 1:NROW(sr)) {  #over all students
    sr[[glue("sh_cor_alt",q)]][[i]]   <- sr[[glue("cr_ans_alt",q)]][[i]]/length(ms[[c(q),"alt_ans"]]) #share of correct answers attained
    sr[[glue("sh_incor_alt",q)]][[i]] <-  (length(sr[[q]][[i]])-sr[[glue("cr_ans_alt",q)]][[i]])/(ms[[c(q),"num_choices"]] - length(ms[[c(q),"alt_ans"]])) #share of incorrect answers chosen
    sr[[glue("net_cor_alt",q)]][[i]] <- max(0,sr[[glue("sh_cor_alt",q)]][[i]]-sr[[glue("sh_incor_alt",q)]][[i]])  #net positive, minimum 0
    sr[[glue("mk_alt",q)]][[i]] <- sr[[glue("net_cor_alt",q)]][[i]] *ms[[c(q),"point_value"]] #multiply by point value
  }
}

```

Take max of marking versions:

```{r}

for(q in rownames(ms)) {   #iterate over all questions 
  for (i in 1:NROW(sr)) {  #over all students
    sr[[glue("mk_max",q)]][[i]] <- max(sr[[glue("mk_",q)]][[i]], sr[[glue("mk_alt",q)]][[i]],ms[[c(q),"free_marks"]],na.rm = TRUE)
  }
  }

```



## Ad-hoc adjustment computation

(Note -- this is not yet adapted to alternate marking version)

```{r adhocadj}

options(digits = 2)

(markpct_p80 <-  sr %>% 
    select(starts_with("markpct_")) %>%
   summarise_all(list(p80 = ~ quantile(.x,.80))) %>% transpose())


#todo: automate this
#for (i in seq_along(sr %>% select(starts_with("markpct_")))){
#adjust[[i]] <- (1-markpct_p80$`80%`$markpct_questions2_p80)*sr$pv_questions2
#}

adhoc_adjust <- (1-markpct_p80$`80%`$markpct_questions2_p80)*sr$pv_questions1 +
  (1-markpct_p80$`80%`$markpct_questions2_p80)*sr$pv_questions2 +
  (1-markpct_p80$`80%`$markpct_questions3_p80)*sr$pv_questions3 +
(1-markpct_p80$`80%`$markpct_questions4_p80)*sr$pv_questions4 +
(1-markpct_p80$`80%`$markpct_questions5_p80)*sr$pv_questions5 +
(1-markpct_p80$`80%`$markpct_questions6_p80)*sr$pv_questions6 +
(1-markpct_p80$`80%`$markpct_questions7_p80)*sr$pv_questions7 +
(1-markpct_p80$`80%`$markpct_questions8_p80)*sr$pv_questions8 +
(1-markpct_p80$`80%`$markpct_questions9_p80)*sr$pv_questions9 +
(1-markpct_p80$`80%`$markpct_questions10_p80)*sr$pv_questions10
(1-markpct_p80$`80%`$markpct_questions11_p80)*sr$pv_questions11 +
(1-markpct_p80$`80%`$markpct_questions12_p80)*sr$pv_questions12 +
(1-markpct_p80$`80%`$markpct_questions13_p80)*sr$pv_questions13 +
(1-markpct_p80$`80%`$markpct_questions14_p80)*sr$pv_questions14 +
(1-markpct_p80$`80%`$markpct_questions15_p80)*sr$pv_questions15 +
(1-markpct_p80$`80%`$markpct_questions16_p80)*sr$pv_questions16 +
(1-markpct_p80$`80%`$markpct_questions17_p80)*sr$pv_questions17

```


## Generate total marks
```{r gentot}
sr <- sr %>%
  mutate(
    total = rowSums(.[grep("mk_maxq*", names(.))], na.rm = TRUE),
    total_adjust = rowSums(.[grep("mk_maxq*", names(.))], na.rm = TRUE)+ adhoc_adjust
  )

```


# Merge in marks from longer answer questions, flag unmerged IDs

```{r merge-long-a}

long_ans <- read.csv(paste(folder,"/",longansfile, sep = ""), header=TRUE,  stringsAsFactors=FALSE, row.names = 1)  %>%
select(-Final_total)  %>%
  as_tibble()

sr_all <- sr %>% mutate(cand_num = as.numeric(`Student Candidate Number`)) %>%
  full_join(long_ans, ., by=c("cand_num")) %>%
    rowwise() %>% 
  mutate(total_mark=sum(B_total, total_adjust, na.rm = TRUE),
         missing_mcq = is.na(total_adjust),
         missing_longans = is.na(B_total)
         ) %>%
  rename(mcq_marks = total_adjust) %>% 
  select(cand_num, SID, matches("cand_num|Choices|B_total|total_mark|mk_max|Mark|total.for|cmt|comments|missing|mcq_marks|B1|B2|B3|B4|B5"),starts_with("q"),-starts_with("qu"),-fields_unmarked) %>%
  select(cand_num,total_mark,starts_with("total"), everything()) %T>%
  print()

```



# Exporting and reporting

## Sorting out missings

```{r}

(missings <- sr_all %>%
  filter(total_mark> 0 & missing_mcq==TRUE | missing_longans==TRUE) %>%
  select(cand_num, missing_mcq, missing_longans,  total_mark) %>%
  arrange(cand_num) )

#93142 = 680018091
#105344 = 670003048
#130436 = ??
#130486 = 680029888


```

## Round mark, calculate mark classification as factor

```{r markclass}

sr_all <- sr_all %>%
      mutate(
        mark_class = cut(round(total_mark), breaks = c(0, 39.99, 49.99, 59.99, 69.99, 100), right=FALSE, labels= c("Fail", "3", "2.2", "2.1", "1st")), 
        total_mark <- round(total_mark)
      )

```


## Export spreadsheet of marks

```{r}
sr_all %>% select(1,SID,"total_mark") %>%
write_excel_csv(file.path(folder,outfile))
```

# Summary statistics

```{r}

options(digits = 2)
sr_all %>%
  group_by() %>% 
  filter(missing_mcq==FALSE & missing_longans==FALSE) %>%
  dplyr::summarise(mean=mean(total_mark, na.rm = TRUE),
                   median=median(total_mark, na.rm = TRUE),
                   sd=sd(total_mark, na.rm = TRUE),
                   p25 = quantile(total_mark,.25, na.rm = TRUE),
                   p75 = quantile(total_mark,.75, na.rm = TRUE))

```


**Mark classifications**

```{r}

sr_all %>%   
  filter(missing_mcq==FALSE & missing_longans==FALSE) %>%
 tabyl(mark_class)


sr_all %>%   
  group_by(mark_class) %>% 
  summarise(min=min(total_mark), max=max(total_mark))

```


## Sumstats by question

```{r}
options(digits = 2)

sr  %>%  
  summarise_at(vars(starts_with("markpct_")), .funs = c(mean="mean")) %>% transpose()


sr %>% select(starts_with("markpct_")) %>%
   summarise_all(list( p80 = ~ quantile(.x,.80))) %>% transpose()

```


## Export one file per student-row (feedback)
 
```{r, eval=FALSE}

student_feedback <-  sr_all %>%
  arrange(cand_num) %>% 
  select(cand_num, mark_class, total_mark, mcq_marks, B_total, Choices, matches("cmt|Comments|B1|B2|B3|B4|B5"), -Other.comments.on.exam, -commentsroundup )   %>%
    rename_all(
    list(
    ~stringr::str_replace_all(.,c('Comments'='cmt','total'='tot','.for.part.B..formula.'='_part_B','Mark.1...out.of.'='mark_B_first_q_from_', 'Mark.2...out.of.'='mark_B_second_q_from_','q(.)c'='q\\1_comments'))
    )) %>% 
  ungroup()  %>% 
  dplyr::arrange(cand_num) 



for (i in 1:nrow(sr_all)) {
    sink(paste0(folder, "/feedback_cand_", student_feedback$cand_num[i], ".txt"))
      print(as.matrix(student_feedback[glue('{i}'),]))
    sink()
}

print(student_feedback[glue('{i}'),])


```

# Admin 

## Select 10 percent of scripts (or 10 scripts) for moderation

Oversample (5x-weight) fails, underweight (1/2) firsts 

```{r}

#set seed before random selection -- OOPS I forgot to do this.... recovering the moderation scripts and merging these back now 

marknums <- read_csv(file.path(folder,"moderation_scripts.csv")) %>%
  select(cand_num)

mod_sample <- sr_all %>%
 left_join(marknums, ., by=c("cand_num")) %>%
  group_by(mark_class) %>% 
  arrange(desc(mark_class), cand_num) %>% 
  select(cand_num, mark_class, total_mark, mcq_marks, B_total, Choices, matches("cmt|Comments|B1|B2|B3|B4|B5") )   


#sample_frac(0.1, weight= 1 + ifelse(mark_class=="Fail",4,0) + ifelse(mark_class=="1st",-1/3,0))
  
mod_sample %>% tabyl(mark_class)

print("collect the scripts:")

mod_sample %>%  ungroup() %>%  select(cand_num) %>% dplyr::arrange(cand_num) %>% print(n=Inf)

mod_sample %>% 
  write_excel_csv(file.path(folder,"moderation_scripts.csv"))


```

## Input random ordering from uni, and put the marks in this order, and then export again

```{r}


sr_all %>%
  arrange(cand_num) %>%
  select(cand_num, total_mark) %>% 
  write_csv(file.path(folder, "marks_only.csv"))


ordering <- read_excel(paste(folder,"/", official_sheet, sep = ""),  col_names = TRUE)  %>%
  lapply(., gsub, pattern = "#", replacement = "", fixed = TRUE) %>% 
  as.tibble() %>% 
   mutate(
    cand_num=as.numeric(`#Cand Key...7`)
  )

ordering$id  <- 1:nrow(ordering)



test <- sr_all %>% 
  select(1,total_mark) %>%  
  rename(Mark=total_mark) %>% 
  anti_join(., ordering, by = c("cand_num"))  %>% 
  distinct(cand_num, .keep_all = FALSE) %>%
  arrange(cand_num) %>% 
  write_csv(file.path(folder, outfile_uni_order))


```

Flag scripts with missing or strange entries:
```{r}
srq <- sr %>%  select(1,starts_with("questions"))
srq$q_missing <- 0

for(q in colnames(srq[2:NCOL(srq)-1])) {   #iterate over all questions
   for (i in 1:NROW(srq)) {  #over all students
      srq[[glue("l_",q)]][[i]]   <-  (length(srq[[glue(q)]][[i]])==0)
   }
}

srq <- srq %>%
  mutate(
    q_missing =    rowSums(select(., starts_with("l_")))
  )

srq %>% filter(q_missing>0) %>% select(starts_with("Student")) %>%  as.matrix() %>% sort() %>%  print()

#filter((length(questions2[[]]) == 0)(questions2)) #if any answer has a blank or a character other than A-E

#126244
```
